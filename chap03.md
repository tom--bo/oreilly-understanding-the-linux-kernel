3章 プロセス
===========
- プロセス=プログラムの実行時におけるインスタンス
  - 16人がviを同時に実行するとプロセス16個(でも1つの実行コード)
- Linuxのコード内ではタスクやスレッドとも呼ばれる



3.1 プロセス、軽量プロセス、スレッド
===========================
- この本でのプロセスの意味はプログラムの実行している状態を指す
  - プロセスは生まれ、生涯を過ごし、子プロセスを生み、最後には死ぬ
  - まるで人のよう（しかし、プロセスの親は1つだけ）
- カーネルから見たときのプロセスの存在意義は、システム資源を割り当てて実体として動かすこと
- プロセス生成時そのプロセスは親のプロセスのアドレス空間の複製を引き継ぐ
- データ領域（スタックとヒープは）別々の複製を持つ
- 子プロセスのメモリ内容は親プロセスからはわからない

古いUNIXはこの単純な仕組みを採用していた

しかし、新しいUNIXは異なる。
新しいUNIXのマルチスレッドのアプリケーションは、データ構造を共有した状態で互いに独立した
多くの処理の流れを持つことが出来る。
このようなシステムでは、プロセスは複数のユーザスレッドを持ち、各スレッドはプロセスの実行の流れを表す。
今ではほとんどのマルチスレッドアプリケーションはpthread(POSIX スレッド)
ライブラリの標準機能を利用して書かれている。

（**軽量プロセス=いわゆるスレッドが導入された**）


古いバージョンのlinuxカーネルはマルチスレッドの機能を持たなかったため、
カーネルから見るとマルチスレッドアプリケーションは1つの通常プロセスだった。
マルチスレッドの複数の処理の流れの生成、操作、スケジュールは、
POSIX互換のpthreadライブラリを呼び出すことで実現されており、全てユーザモードで動作していた。
そのため、アプリケーション製作者は、賢いノンブロッキング手法を実装し、プログラムの走行可能状態を維持していた。

（**要するにコンテキストスイッチ等をアプリ内で実装していたので大変だった**）

（新しい）linuxはマルチスレッドのために軽量プロセスを提供している。
複数の軽量プロセスはアドレス空間やオープンしているファイル等の資源を共有する。
そして、一方が共有資源を変更すると、排他制御は必要だが、他方の軽量プロセスからもすぐにその変更が分かる。


スレッドを軽量プロセスとして動かすことでマルチスレッドアプリケーションを素直に実行することが出来る。
メモリアドレス空間オープンファイルを共有することで、アプリケーションの同じデータを参照できる。
またカーネルは各スレッドを独立してスケジューリングし、あるスレッドが待ち状態に入っても他方のスレッドを
動作させることが出来る。

(**カーネルがスレッドを管理してくれるようになったので楽になった**)

軽量プロセスを扱うposic互換のライブラリの実装
- linuxthreadsライブラリ
- natibeposixスレッドライブラリ
- IBMの次世代POSIXスレッドパッケージ

posix互換のマルチスレッドアプリケーションは、スレッドグループを扱うカーネルによって最適に制御される。
linuxのスレッドグループは基本的には軽量プロセスの集合であり、
linuxgetpid kill _exit()等のいくつかのシステムコールはスレッドグループ単位でまとめて処理を行う。
これについては後述する


3.2 プロセスディスクリプタ
=====
カーネルはプロセスを管理するために、各プロセスが何を行っているかを熟知している必要がある。
- プロセスの属性
- CPU上で実行されているか
- 待ち状態に入っているか
- どのアドレス空間に割り当てられているか
- どのファイルへのアクセスが許可されているか
- 等
 

これらの情報はtask_struct型の**プロセスディスクリプタ**に格納される
この構造体のメンバには**1つのプロセスに関するすべての情報**が含まれている。
プロセスディスクリプタは非常に多くの情報が核のされているためかなり複雑

ここに図がはいる
（代用）
```
task_struct{
    state           (プロセスの実行状態)
    *thread_info -> thread_info（プロセスに対応する低水準情報）
    usage 
    flags
    ...
    *run_list   -> 
    *tasks      ->
    ...
    *mm         -> mm_struct(メモリリージョンディスクリプタへのポインタ)
    ..
    *real_parent    ->
    *parent         ->
    ...
    *tty    ->tty_struct（プロセスに対応する制御端末）
    ...
    thread
    ...
    *fs         -> fs_struct（カレントディレクトリ）
    *files      -> files_struct（ファイルディスクリプタへのポインタ）
    ...
    *signal     -> signal_struct(受信シグナル)
    pending
    ...
}

```
この章ではプロセスの状態を表す2種類のメンバとプロセスの親子関係について説明する。

### 3.2.1 プロセスの状態
#### プロセスディスクリプタのstateメンバ
プロセスの現在の状態が、フラグの集まり(ビット列)として格納されている
linuxの現在のバージョンではフラグは排他的であり、必ずどれか1つのフラグのみが設定される。
##### stateに格納される値
- TASK_RUNNING
  - プロセスはCPU上で実行中あるいは実行待ちの状態
- TASK_INTERRUPTIBLE
  - ある条件が成り立つのを一時停止（休止）して待ち合わせている状態
  - ハードウェア割り込み、目的の資源の解放、シグナルの受信などによりプロセスが起こされる
- TASK_UNINTERRUPTIBLE
  - TASK_INTERRUPTIBLEと同様だが、シグナルを受信しても状態が変わらない
  - デバイスファイルやファイルI/Oの処理する際には割り込まれないようにこの状態になることが多い
- TASK_STOPED
  - 停止中
  - SIGSTOP, SIGTSTP, SIGTTIN, SIGTTOUシグナルを受信するとこの状態になる
- TASK_TRACED
  - デバッガ等ほかのプロセスに監視されている場合にこの状態になる
- EXIT_ZOMBIE
  - 実行が終了しているが、親プロセスがwait4(),waitpid()をまだ発効しておらず、終了プロセスの情報を得ていない状態
  - 親プロセスが必要とする可能性があるため,wait()系のシステムコールが呼ばれるまではカーネルは終了したプロセスを解放できない
- EXIT_DEAD
  - waitが呼ばれ、プロセスが削除された状態
  - EXIT_ZOMBIEがwaitで開放された場合になる
  - 同じプロセスのほかのスレッドが再びwaitしないために存在

カーネルは**set_task_state**マクロ（他のプロセスの実行状態の変更）や**set_current_state**マクロ（今のプロセスの実行状態の変更）等を利用して指定したプログラムの状態を設定する。
このマクロはコンパイラやCPU制御回路によってほかの命令と順序が入れ替わらないことを保障されている。
5章で詳細について触れる
  

### 3.2.2 プロセスの識別
プロセスは、**プロセスディスクリプタポインタ**と**プロセスID**の両方で識別できる

##### <u>プロセスディスクリプタポインタ</u>

独立にスケジューリング可能な各実行コンテキストは、基本的にそれぞれプロセスディスクリプタが割り当てられる。
したがって、多くのカーネルデータを共有する軽量プロセスも同様にtask_struct（プロセスディスクリプタ）を割り当てられる。
- プロセスとプロセスディスクリプタは必ず1対1で対応するため、カーネルはtask_struct構造体の32bitのアドレスを使用してプロセスを識別している
- このアドレスはプロセスディスクリプタポインタと呼ばれる

**カ―ネルは多くの場合このプロセスディスクリプタポインタを使用してプロセスを参照している**。


##### <u>プロセスID</u>
一般的にUNIX系のOSではユーザは、プロセスをプロセスIDで識別する。
このプロセスIDはプロセスディスクリプタのpidメンバに格納されている。

- PIDは順番に割り当てられた数字で、直前に生成されたプロセスのPIDに1を加えた値になる。
- 当然PIDの値には上限があり、カーネルはこの上限に達した時に、使われていないPIDの再利用を行う。
- 初期値は32,767でありこの値は/proc/sys/kernel/pid_maxを変更することで変えられる。
- PIDを再利用するときはpidmap_arrayビットマップを参照している。
  - このビットマップは使用中のPIDと未使用のPIDを表している。
  - 64bitではビットマップ用にページが追加される。
  - これらのページが解放されることはない。
  - (**巨大なbit配列で使用中かどうかを保持しているため再利用ができるということ**)

##### <u>スレッドグループ</u>

ところで、最初に触れたように、Linuxは各プロセス及び各軽量プロセスに異なるPIDを付与する。
この方式によりシステム上のすべての実行コンテキストを一意に識別できるので、非常に大きな自由度が得られる。
しかしながら、軽量プロセスにもpidが割り振られることで問題が発生する。
なぜなら、UNIXプログラマは同じグループのスレッドは同じPIDを持っていることを期待しているためである。
加えて、POSIXの1003.1c規格においても、「マルチスレッドアプリケーションのすべてのスレッドは同じPIDを持つ」と規定されている。

そこで、Linuxはこの規格に準拠するためスレッドグループを使用している
スレッドグループでは、共有する識別としてグループの最初の軽量プロセスであるスレッドグループリーダのPIDを使用している。
この識別子は、各プロセスディスクリプタのtgidメンバに格納されるようになっており、
また、getpidシステムコールは、カレントプロセスのpidの値ではなく、このtgidの値を返すようになっている。
そのため、マルチスレッドアプリケーションのすべてのスレッドは同じ識別子を共有できる。

なお大部分のプロセスはシングルスレッドであるが、これらのプロセスも1つのプロセスからなるグループに所属しているように扱い、
tgidとpidに同じ値を持つ。

#### 3.2.2.1 プロセスディスクリプタ処理
プロセスは動的な存在であり、生存時間は数ミリから数か月ほどである。
カーネルはこれらのプロセスを同時に多く扱えなければならない。
この節ではプロセスに割り当てるメモリの扱いについて説明する。

まず、プロセスディスクリプタはカーネルに静的に割り当てられたメモリ用域ではなく、動的に確保されたメモリに格納される。
また、linuxは各プロセスにプロセスディスクリプタとは別の1つのメモリ領域を割り当ててプロセスディスクリプタとリンクする。
このメモリ領域には*thread_info構造体*（動作させているプロセスに関する情報を持つ）と*カーネルモードプロセススタック*が割り付けられる。

- この領域は8,192バイトでページフレーム二つ分の大きさを持つ
- カーネルはこの8KBの領域を2^13の倍数のアドレス境界から連続した2つのページフレームに置く
  - この方式は空きメモリを断片化させやすいため、動的メモリが残り少ない場合に問題を起こしうる。（8章）
  - 80x86アーキテクチャではこの領域のサイズを変更でき、1つのページフレームに収めるようにカーネルを構成することもできる。


##### <u>カーネルスタック</u>
 
2章で2.3で触れたように、カーネルモードのプロセスはユーザモードのプロセスが使用するスタックとは異なる、
カーネルデータセグメントにあるスタックを使用する。その時に使用するのが、ここで割り付けているカーネルスタックである。
カーネルの実行パスには、2000倍と程度の容量しか必要としないため、スタックが8KBでも十分な大きさである。

 
図をはさむ

プロセスのメモリ領域での2つのデータ構造がどのように入っているのかを表しているのがこの図
thread_info構造体はメモリ領域の先頭に格納し、スタックは末尾から定位アドレス方向に伸びていく


- espレジスタはCPUのスタックポインタであり、スタックの先頭位置を指すために使われる
- 80x86のシステムではスタックはメモリ領域の最後(アドレスの大きい方)から始まり、先頭に向かって成長していく
- プロセスのカーネルスタックは、ユーザモードからカーネルモードへ切り替わった直後は空なのでespレジスタはスタックの末尾+1のアドレスを指す
- espの値はスタックにデータが格納されると減少する。
- C言語ではプロセスのthread_info構造体とカーネルスタックを以下のような共用体で表すことができる。
```
union thread_union{
    struct thread_info thread_info;
    unsigned long stack[2048];
};
```
なおカーネルは*alloc_thread_info*と*free_thread_info*マクロを使って、thread_infoと
カーネルスタック用の領域の確保と開放を行っている。


#### 3.2.2.2 カレントプロセスの識別

上述のようにthread_info構造体とカーネルモードスタックを対にして管理することには大きく利点がある。
カーネルが、espレジスタの値から現在動作しているプロセスのthread_info構造体のアドレスを簡単に求めることができるためある。

*thread_union構造体*の長さが8KBのときはespレジスタの下位13ビットを、4KBのときは下位12bitを0でマスクすることでthread_info構造体
のアドレスを求められるのである。
この処理を行う**current_thread_info**関数は次のように展開される

```
movl $0xffffe000, %ecx
andl %esp, %ecx
movl %ecx,p
```
この処理によりpにはそのCPUで処理しているプロセスのthread_info構造体のポインタが格納される。

また、多くの場合カーネルはthread_infoのアドレスよりもプロセスディスクリプタのアドレスを必要とする。
その際の処理を行うcurrentマクロは展開すると次のようになる。
```
movl $0xffffe000, %ecx
andl %esp, %ecx
movl (%ecx),p
```
（プロセスディスクリプタへのポインタはthread_infoの先頭に格納されているためこう書ける）

このcurrentマクロはプロセスディスクリプタのプレフィックスとしてカーネルコードに頻繁に登場する。
例えばcurrent->pidとすれば現在CPU上動作するプロセスのIDを取得できる。

##### <u>マルチプロセッサシステムでの利点</u>

カーネルスタックとプロセスディスクリプタを一緒に格納する利点としては、
このほかにもマルチプロセッサシステム対応の場合があげられる。
初期のlinuxではカーネルスタックとプロセスディスクリプタは別々に格納されていたため、
代わりにcurrentというグローバルなスタティック変数を導入して動作中のプロセスのプロセスディスクリプタを識別していた。
そのため、マルチプロセッサシステムの場合はcurrentを配列として定義し、
CPU一つ一つと配列の1要素を対応させていた。

（thread_unionを使ったメモリ割り付けを行うことで、グローバル空間に現在実行中のPIDを置く必要がなくなり、管理が楽になった）



#### 3.2.2.3 双方向リスト
カーネルがどのようにプロセスを扱っているかを理解するためには、
双方向リストを実現する特殊なデータ構造について知る必要がある。
そのため、この説ではカーネル内で双方向リストを実現する特殊なデータ構造について説明する。

リストを実現するためには、リストの初期化、挿入、削除、操作といったプリミティブな処理が必要であるが、
リスト処理のためにプリミティブな処理を実装するのは時間もメモリの無駄にしてしまう。

そのためlinuxカーネルは、リスト処理のためのlist_headデータ構造を用意している。
list_headはnextメンバとprevメンバを持ち、これらは一般的な双方向リストの前方と後方を指すポインタに相当する。
ここで重要なのは、list_headのポインタ(next, prev)は別のlist_head（を持つオブジェクト）内の同じメンバを指しており、
list_headデータ構造の先頭を指しているわけでないことである。
（図3-3を参照）

>（意味不明なので解説）
>
>list_headの定義は以下のようなもの。
>```
>struct list_head {
>	struct list_head *next, *prev;
>};
>```
>これだけでは一見するとどのようにリストを作るのかわかりづらい。
>
>例えばlist_headの要素を表す構造体は以下のようにかける。
>```
>>struct test_data {
>	int no;
>	struct list_head list;
>};
>```
>
>リスト要素自体を表すオブジェクトが、次のオブジェクトへのポインタと値として持たせたい
>オブジェクトのポインタを持つのでなく、
>リスト要素にしたいオブジェクトにlist_head型のオブジェクトをメンバとして持たせるということ。
>
>test_dataのlistメンバのnextには、リストの次の要素が持つlistメンバへのポインタが入っている。


新しいリストはLIST_HEAD(list_name)マクロで生成でき、このマクロはlist_nameという名前のlist_head型変数を宣言する。
この変数はダミーの先頭要素で新しいリストの先頭になる。
提供されているプリミティブ関数とマクロは以下のものがある。

```
list_add(n,p)       //pの直後にnをそうにゅう
list_add_tail(n,p)  //pの直前にnを挿入
list_del(p)         //pが指す要素を削除
list_empty(p)       //pが示すリストが空かどうか確認
list_entry(p,t,m)   //list_head型のpからリストの要素であるt型のオブジェクトを取り出す。
                    //mはtが持つlist_head型の変数名（文字列（マクロなので））
list_for_each(p,h)  //リストの先頭hから要素を走査してlist_head型メンバへのポインタをpに取り出す
list_for_each_entry(p,h,m)//上と同様だが、list_head型でなくリスト要素型のポインタを取り出す

```

>追記情報
>
>list_entryとlist_for_eachの仕組みは以下のようになっている。
>
>それぞれのマクロの第三引数では、リスト要素型が持つlist_head型メンバの変数名mを指定しているが、
>これはコンパイラが提供するoffsetマクロにより、リスト要素型の先頭から変数mの間のアドレスの差
>を取得し、第一引数のlist_headオブジェクトの位置するアドレスからそのアドレス分をさかのぼることで
>実装されている。




Linuxカーネル2.6からは別の種類の双方向リストを提供しており、
この他にも主にハッシュテーブルで使用するhlist_headデータ構造がある。
list_headを使うリストとの大きな違いはリストが循環していないことである。
このhlist_headのリスト要素は、hlist_nodeのデータ構造を持っており、
hlist_nodeはnextとpprevメンバを持つ。
この操作には上に挙げた関数やマクロと似たhlist_add_head(),hlist_del(),hlist_entry等がある。



#### 3.2.2.4 プロセスリスト
双方向リストの例として、存在するすべてのプロセスディスクリプタをリンクするプロセスリストを挙げる。
プロセスディスクリプタを現すtask_struct構造体はlist_head型のtasksメンバを持ち、
このtasksメンバのprevメンバがひとつ前のtask_structを指し、nextメンバが次のtask_structを指している。

プロセスリストの先頭はtask_struct型のinit_taskであり、いわゆるプロセス0である。
init_taskのtasks->prevはリストの末尾のプロセスディスクリプタのtasksを指す。
SET_LIMKおよびREMOVEマクロがプロセスディスクリプタをプロセスリストに挿入/削除するために使用される。
そのほかにもfor_each_processがあり次のように定義される

```
#define for_each_process(p) \
for(p=&init_task; (p=list_entry((p)->tasks.next, struct task_struct, task) != &init_task)
```


#### 3.2.2.5 TASK_RUNNING状態のプロセスリスト
カーネルが次に実行する新しいプロセスを探す際には、
ｓたてがTASK_RUNNINGとなっている実行可能プロセスのみを調べる。

初期のLinuxでは、実行キューとなるリストにすべての実行可能プロセスをおさめ、
プロセスの優先度にしたがってスケジューリングするためにキューをすべてを走査する必要があった。
2.6では異なる実装をしており、この詳細は7章で述べる。

スケジューラの高速化の秘訣は、実行キューを実行可能プロセスの優先度ごとのリストに分割
したことである。各プロセスディスクリプタ(task_struct)はlist_head型のメンバrun_listメンバを持っている。
プロセスの優先度がk(0~139)の間に収まっている時、このrun_listは優先度kの実行可能プロセスのリストにリンクしている。
（余談　マルチコア環境では各コアが実行キューを持つ。このようにデータ構造を複雑化することで性能を向上できる）

また、カーネルはprio_array_tデータ構造のオブジェクトを1つ確保し、これですべてのrun_listを管理している。

```
prio_array_t
    int                     nr_active       //リストにリンクされたプロセスディスクリプタの総数
    unsigned long[5]        bitmap          //優先度のビットマップ(140個フラグがあり1のリストを処理する)
    struct list_head[140]   queue;          //140この優先度リストの先頭（実体あり）
```

enqueue_task(p, array)関数はrequeueのリストにtask_struct型pを挿入する。
以下のコードと同等である。
```
list_add_tail(&p->runlist, &array->queue[p->prio]);
__set_bit(p->prio, array->bitmap);
array->nr_active++;
p->array=array;
```
task_structのメンバprioはそのプロセスの優先度を表し
メンバarrayは現在の実行キューのprio_array_tデータ構造を指す。




### 3.2.3 プロセスの親子関係
プログラムから生成されたプロセスには親子関係がある。
また親が複数の子プロセスを立てると兄弟関係ができる。
プロセスディスクリプタにはこうした関係を表すいくつかのメンバがある。
それに関するメンバを以下に示す（表3-3）
なおプロセス0,1(init)はカーネルが生成し、プロセス1はそのほかすべてのプロセスの先祖である。

```
real_parent : プロセスPを生成したプロセスのプロセスディスクリプタを指す（親が存在しない場合はプロセス1を指す）
parent : プロセスの現在の親を指す。ptraceシステムコール等を行うとreal_parentと異なる値になる。
children : 生成したすべての子プロセスを含むリストの先頭
sibling : 同じ親を持つプロセスのリストの次の要素と前の要素に対するポインタ

```
親子、兄弟関係以外にも、プロセス間の関係として、プロセスグループやログインセッションリーダ、スレッドグループのリーダ等の関係が存在する。
また他のプロセスの実行を追跡することもある。
これらを表すプロセスディスクリプタのメンバに以下のものがある
```
group_leader        グループリーダのプロセスディスクリプタへのポインタ
signal->pgrp        グループリーダのPID
tgid                スレッドグループリーダのID
signal->session     ログインセッションリーダのPID
ptrace_children     子プロセスのうちデバッガで追跡中のプロセスリストの先頭
ptrace_list         子プロセスのうちデバッガで追跡中のプロセスリストのリスト要素
```

#### 3.2.3.1 pidhashテーブルとリスト
カーネルがkillシステムコールを処理するときなどに、PIDから対応するプロセスディスクリプタを必要とするときがある。
P1がP2にシグナルを送るとき、P2のPIDからP2のプロセスディスクリプタを求め、
その保留中シグナルを格納するデータへのポインタを得る必要があるのである。

このときプロセスリストを操作してプロセスディスクリプタのpidメンバを確認することはあまり効率的ではない。
そこで4つのハッシュテーブルが導入された。

```
ハッシュテーブル名  対応するプロセスディスクリプタのメンバ

PIDTYPE_PID:        PIDとひもづくハッシュテーブルの要素
PIDTYPE_TGID:       tgid（スレッドグループリーダPID）とひもづく
PIDTYPE_PFID:       pfrp(グループリーダPID)とひもづく
PIDTYPE_SID:        session（セッションリーダPID）とひもづく
```
（これらの値をキーとしてプロセスディスクリプタが管理されている）

これらのハッシュテーブルは、カーネルの初期化時に自動的に確保され、
それらのアドレスはpid_hash配列に格納される。（グローバル空間に4つのハッシュテーブルがある）
1つのハッシュテーブルは4つのページフレームを使用し、それぞれ2048このエントリを持つ。
pidはpid_hashfnマクロより、0~2^11-1=2047までの値にハッシュ化される。
（プロセスIDは32768であるが、実際に動くプロセス数は少ないためこの方がメモリの有効活用ができる）


もちろん異なるキーでも同じインデックスにハッシュされることがあり、これを衝突と呼ぶ。
衝突した場合、linuxではチェイン法（オープンハッシュをを用いる）
（チェイン法の詳細はない）
ハッシュテーブルの各エントリには、衝突したプロセスディスクリプタの双方向リストの先頭が格納されている。
例えばpid2890と29384のプロセスはテーブルの200番目に格納されるが、それぞれのリストの先頭が格納される。

例えばカーネルがあるスレッドグループに属するすべてのプロセスを検索するときを考える。
スレッドグループ番号でPIDハッシュテーブルを検索すると、1つのプロセスディスクリプタが見つかる。
これがスレッドグループリーダのプロセスディスクリプタである。
このスレッドグループに属する他のプロセスを探す場合、tgidハッシュテーブルで検索すればよい。

子のハッシュテーブルにかかわるtask_structメンバは4つのpid構造体のであり、
この配列はtask_structのpidsメンバにおかれている
```
pids
    int nr;                         //PID
    struct hlist_node pid_chain;    //ハッシュチェインリストの前後への要素へのリンクをもつ要素
    struct list_head;               //属するリストにリンクする要素
```

### 3.2.4 プロセスの管理方法
TASK_RUNNING状態の全プロセスを、実行キューリストを利用してグループ化します。
（3.2.2.5で少しふれた）
他の状態のプロセスをグループ化するには、その状態ごとに異なる方法が必要である。
- TASK_STOPED, EXIT_ZONBIE, EXIT_DEAD
  - これらは専用のリストに登録しない。PIDか親プロセスと子プロセスのリストを通して操作する
- TASK_INTERRUPTIBLE, TASK_UNINTERRUPTIBLE
  - プロセス状態だけではプロセスを見つけるための十分な情報を提供できないため、**待ちキュープロセスのリスト**が必要になる。

#### 3.2.4.1 待ちキュー（待ち行列）
待ちキューは割り込み処理、プロセスの動機等に待ちキューを使用する。
FILE I/O、システム資源の解放等ある事象が発生するまで待つ処理に使用される。
特定の事象を待つプロセスは自身を適切な待ちキューに入れて処理を任せ、その後はある条件が真になった時に起こされる。

待ちキューは双方向リストとして実装されており、各要素はプロセスディスクリプタへのポインタを持つ。
各待ちキューは待ちキューの先頭で識別される。
銭湯はwait_queue_head_t型のデータ構造である。

```
struct __wait_queue_head{
    spinlock_t lock;
    struct list_head task_list;
}
typedef struct __wait_queue_head wait_queue_head_t;
```

待ちキューは通常のカーネル関数だけでなく、割り込みハンドらからも更新されるため、
双方向リストを同時アクセスから保護する必要があります（5章）。
同期は待ちキュー内のスピンロックによって行います。
待ちキューの要素の方は wait_queue_tである。
```

struct __wait_queue{
    unsigned int flags;
    struct task_struct * task;
    wait_queue_func_t func;
    struct list_head task_list;
}

```

待ちキュー内のプロセスはそれぞれ何かの事象の発生を待ち合わせており、
taskメンバはそのプロセスディスクリプタを表している。そして、task_listは同じ事象の発生を
待ち合わせているプロセスのリスト中の要素を指すポインタである。

しかし、待ちキュー上のすべてのプロセスを起こすことは常に好都合であるとは限らない。
例えばある資源の解放を複数のプロセスが待っている場合、次に起床させるのは待ちキューの先頭のプロセスだけ
を起床する方が理にかなっている。
するとこのプロセスが資源を利用し、他のプロセスはマチツヅケルことになる。
（この方法により大群問題 thundering herdを起こさずに済んでいる）

また、プロセスの待ち状態は2種類用意されています。
それは排他的待ちプロセスと排他的待ちでないプロセスです。
これらはflagsメンバによって区別され、1のとき排他的待ちと扱われます。
これらの区別は、一度に1つのプロセスしか利用できない資源かどうかによって行われています。
例えば一連のディスクブロック転送の終了を待ち合わせるプロセスのグループは排他的待ちでないプロセスです。


#### 3.2.4.2 待ちキュー操作
待ちキューで待ち状態になっているプロセスの起床方法について説明する。

待ちキューの頭はDECLARE_WAIT_QUEUE_HEAD(name)マクロで定義できる。
このマクロはnameという名の新しい待ちキューの頭を性的に宣言し、lockメンバとtask_listメンバを初期化する。
init_waitqueue_head()は動的に確保した待ちキューの頭を初期化する。
init_waitqueue_entry(q,p)関数は、wait_queue_t構造体qを次のように初期化する。

```
q->flafs=0;
q->task=p;
q->func=default_wake_function;
```
排他的でない待ちプロセスpは、default_wake_function()によって起こすことができる
（よくわからない）

他の方法として、
DEFINE_WAITマクロを利用して待ちキュー要素wait_queue_t変数を宣言することができます。
これは作成した変数の値を現在のプロセスのディスクリプタと起床関数autoremove_wake_functionで初期化する。
このautoremove_wake_functionはdefault_wake_function()を世ヴィ出して待ち状態のプロセスを起こし、
その後待ちキューから要素を外します。


- add_wait_queue() : 排他的でない待ちプロセスを待ちキューの先頭に挿入
- add_wait_queue_exclusive() : 排他的待ちプロセスを待ちキューの末尾に挿入
- remove_wai_queue() : 待ちキューからプロセスを外す
- waitqueue_actinve() : 待ちキューが空かどうか調べる

- sleep_on() : カレントプロセスをTASK_UNINTERRUPTIBLEに設定し、指定した待ちキューに追加する
- interruptible_sleep_on : シグナルを受け取るバージョン
- sleep_on_timeout : タイムアウトを指定できる
- prepare_to_wait,prepare_to_wait_exclusive,finish_wait : Linux2.6で追加された状態を任意に指定できる
- wait_event, wait_event_interruptible : このマクロは呼び出したプロセスを条件が成立するまで待ち続けさせる。

ここで注意すべきなのは、
> sleep_on()などの関数は、条件を確認した結果、その条件が成立していない場合にプロセスを待ち状態にする、という
> 一般的な状況では使えません。よく知られているように競合状態が発生するためです。









### プロセスの資源利用制限